ğŸ“ Growth_Copilot Proje KlasÃ¶r YapÄ±sÄ±

```bash
Growth_Copilot/
â”‚
â”œâ”€â”€ config.py
â”‚   # API token'larÄ±nÄ± os.getenv ile Ã§eken yapÄ±
â”‚   # GitHub Secrets Ã¼zerinden environment variable olarak alÄ±nÄ±r
â”‚   # Shopify iÃ§in birden fazla ad account tanÄ±mlanabilir
â”‚   # Ä°kinci hesabÄ±n token'larÄ± yorum satÄ±rÄ± olarak ÅŸablon halinde tutulabilir
â”‚
â”œâ”€â”€ app.py
â”‚   # Flask uygulamasÄ±
â”‚   # JSON endpoint'leri (GPT'ye veri sunar)
â”‚   # /data/... â†’ JSON verisi dÃ¶ner
â”‚   # /export-excel/... â†’ Excel dosyasÄ± dÃ¶ner (RAM uzerinde oluÅŸur, diske yazÄ±lmaz)
â”‚   # /search-vector â†’ FAISS + Embedding arama endpoint'i (RAG)
â”‚   # /search-vector, Vectors/faiss_index.bin dosyasÄ±nÄ± kullanarak semantik arama yapar
â”‚   # Ã–rnek: /export-excel/meta-marketing?min_spend=1000
â”‚
â”œâ”€â”€ .well-known/
â”‚   # GPT Plugin tarafÄ±ndan tanÄ±nan metadata ve OpenAPI tanÄ±mlarÄ±
â”‚   â”œâ”€â”€ ai-plugin.json
â”‚   â”‚   # GPT Plugin manifest dosyasÄ± (name_for_model, description_for_model, auth, logo_url, contact_email)
â”‚   â””â”€â”€ openapi.json
â”‚       # TÃ¼m endpoint'leri tanÄ±mlayan OpenAPI 3.1 schema (data, excel, vector search)
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ fetch_data.yml
â”‚           # GitHub Actions cronjob yapÄ±landÄ±rmasÄ±
â”‚           # Her sabah TÃ¼rkiye saatine gÃ¶re 06:00'da ilgili API'lere istek atar
â”‚           # Gelen veriyi Data/ klasÃ¶rÃ¼nÃ¼ JSON olarak kaydeder
â”‚           # âœ” API'lerden sadece bir Ã–NCEKÄ° gÃ¼nÃ¼n verileri Ã§ekilir
â”‚           # âœ” Daha Ã¶nceki verilerin Ã¼zerine eklenir, tekrar veri Ã§ekilmez
â”‚           # âœ” Ä°lk veri Ã§ekiminde, sistem 2025-01-01 tarihinden baÅŸlayarak bugÃ¼nden bir Ã¶nceki gÃ¼ne kadar olan verileri toplu olarak Ã§eker
â”‚           # âœ” Her bir veri kaydÄ±nÄ±n iÃ§inde "veri tarihi" mutlaka yer alÄ±r (trend analizleri iÃ§in zorunludur)
â”‚           # âœ¨ KPI ve parametre yapÄ±sÄ± ilk aÅŸamada kod Ã¼retici ajan tarafÄ±ndan Ã¶nerildiÄŸi gibi uygulanacaktÄ±r. Daha sonra deÄŸiÅŸtirilebilir.
â”‚           # âœ¨ Shopify verileri e-ticaret iÅŸimin merkezinde olduÄŸu iÃ§in, GPT'nin strateji Ã¼retebilmesi adÄ±na doÄŸru KPI'lara odaklanÄ±lmasÄ± saÄŸlanacaktÄ±r. E-ticaret iÃ§in endÃ¼stri standartÄ± KPI'lar kullanÄ±lmalÄ±dÄ±r.
â”‚           # âœ¨ fetch_data.py dosyalarÄ±nda oluÅŸturulacak tÃ¼m veri satÄ±rlarÄ±nda "veri tarihi" mutlaka bulunmalÄ±dÄ±r. GPT'nin zamana dayalÄ± analiz Ã¼retebilmesi iÃ§in bu zorunludur.
â”‚
â”œâ”€â”€ Data/
â”‚   # Parquet formatÄ±nda veri klasÃ¶rÃ¼ (GPT bu dosyalarÄ± okur)
â”‚   # Her API modÃ¼lÃ¼ kendi verisini buraya kaydeder
â”‚   â”œâ”€â”€ Meta_Marketing_Data.parquet
â”‚   â”œâ”€â”€ Meta_Insights_Data.parquet
â”‚   â””â”€â”€ Shopify_Data.parquet
â”‚
â”œâ”€â”€ Vectors/
â”‚   # OpenAI Embedding + FAISS tabanlÄ± vektÃ¶rel arama yapÄ±sÄ±
â”‚   # Verilerden anlamlÄ± cÃ¼mle bloklarÄ± Ã§Ä±karÄ±lÄ±r, OpenAI Embedding ile vektÃ¶re Ã§evrilir
â”‚   # FAISS index'e yazÄ±lÄ±r ve search-vector endpoint'inde kullanÄ±lÄ±r
â”‚   # FAISS index gÃ¼ncelleme iÅŸlemi haftada bir Pazartesi sabahÄ± 06:00'da Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r
â”‚   # âœ” Haftada sadece 5-10 yeni kampanya varsa, bu periyot yeterlidir. GÃ¼nlÃ¼k yenilemeye gerek yoktur.
â”‚   â”œâ”€â”€ faiss_index.bin
â”‚   â””â”€â”€ generate_faiss_index.py
â”‚       # Data/ klasÃ¶rÃ¼ndeki JSON'larÄ± doÄŸrusal cÃ¼mle bloklarÄ±na Ã§evirir
â”‚       # Embedding API ile vektÃ¶rleÅŸtirir, faiss_index.bin olarak kaydeder
â”‚
â”œâ”€â”€ Meta_Marketing_API/
â”‚   â””â”€â”€ fetch_data.py
â”‚       # Meta Marketing API'ye istek atar
â”‚       # Gelen cevabÄ± Data/Meta_Marketing_Data.parquet olarak kaydeder
â”‚
â”œâ”€â”€ Meta_Insights_API/
â”‚   â””â”€â”€ fetch_data.py
â”‚       # Meta Insights API veri Ã§ekme scripti
â”‚       # Verileri Data/Meta_Insights_Data.parquet olarak kaydeder
â”‚
â”œâ”€â”€ Shopify_Admin_API/
â”‚   â””â”€â”€ fetch_data.py
â”‚       # Shopify Admin API veri Ã§ekme scripti
â”‚       # Verileri Data/Shopify_Data.parquet olarak kaydeder
â”‚       # âœ” Birden fazla Shopify hesabÄ±ndan veri Ã§ekmeye uygun yapÄ±dadÄ±r
â”‚       # âœ” Ä°kinci veya yeni account token'larÄ± config.py'de yorum satÄ±rÄ± ile eklenebilir
â”‚       # âœ” fetch_data.py iÃ§inde birden fazla token iÃ§in istek dÃ¶ngÃ¼sÃ¼ desteklenir, ama varsayÄ±lan tek hesap Ã§ekilir
â”‚
â”œâ”€â”€ README.md
â”‚   # Proje aÃ§Ä±klamalarÄ± ve kullanÄ±m kÄ±lavuzu
â”‚
â””â”€â”€ .gitignore
    # .env gibi hassas dosyalarÄ±n git'e eklenmesini engeller
```

> ğŸ“Œ Bu yapÄ± sayesinde:
> - Tek repo, tek config, tek secrets sistemiyle gÃ¼venli mimari saÄŸlanÄ±r
> - TÃ¼m JSON veriler GPT iÃ§in eriÅŸilebilir durumdadÄ±r
> - Ä°stenirse Excel olarak da indirilebilir, filtre uygulanabilir
> - Her API kendi fetch scriptine sahiptir ve Data/ iÃ§ine yazar
> - GPT Plugin iÃ§in gerekli endpoint'ler /data/..., /export-excel/... ve /search-vector altÄ±nda sunulur
> - Excel dosyasÄ± RAM Ã¼zerinde oluÅŸturulur, diske yazÄ±lmaz
> - VektÃ¶rel arama ve semantik analiz iÃ§in FAISS + Embedding tabanlÄ± RAG sistemi entegredir
> - generate_faiss_index.py dosyasÄ± FAISS index oluÅŸturur, app.py bu index ile semantik arama yapar
> - .well-known/ klasÃ¶rÃ¼ GPT Plugin entegrasyonu iÃ§in gerekli olan ai-plugin.json ve openapi.json dosyalarÄ±nÄ± iÃ§erir
> - âœ¨ Data/ klasÃ¶rÃ¼ her sabah TÃ¼rkiye saatine gÃ¶re 06:00'da otomatik gÃ¼ncellenir; FAISS index ise sadece haftada 1 (Pazartesi 06:00) gÃ¼ncellenir. Bu durum, haftada 5-10 kampanya verisi deÄŸiÅŸimi olan yapÄ±lar iÃ§in yeterlidir.